[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prompts, Dreams, and Me",
    "section": "",
    "text": "What If Shakespeare Talked About Cloud Computing?\n\n\n\nLLMs\n\nprompting\n\ncross-culture\n\ntranslation\n\nreflection\n\n\n\nWhat happens when you force an AI to explain blockchain like Socrates, or describe cloud computing in the style of Shakespeare?\n\n\n\n\n\nSep 19, 2025\n\n\nHanxi\n\n\n\n\n\n\n\n\n\n\n\n\nLost in Translation: AI After MIIS\n\n\n\nLLMs\n\nprompting\n\ntalk with AI\n\ncross-culture\n\ntranslation\n\nNews\n\n\n\nWhen the bridge of authority disappears, how will AI ‘transfer’ language?\n\n\n\n\n\nSep 17, 2025\n\n\nHanxi\n\n\n\n\n\n\n\n\n\n\n\n\nWhen AI Meets MBTI （Part 3)\n\n\n\nLLMs\n\nprompting\n\nSeries\n\nreflection\n\nPsychology\n\n\n\nChatGPT can slip into personality with prompts, but hey, don’t we do the same with MBTI labels?\n\n\n\n\n\nSep 15, 2025\n\n\nHanxi\n\n\n\n\n\n\n\n\n\n\n\n\nWhen AI Meets MBTI （Part 2)\n\n\n\nLLMs\n\nprompting\n\nSeries\n\nStatistics\n\nPsychology\n\nSurvey\n\n\n\nIn Part 2, GPT stays silent on its identity and the fun begins when we project one onto it\n\n\n\n\n\nSep 14, 2025\n\n\nHanxi\n\n\n\n\n\n\n\n\n\n\n\n\nWhen AI Meets MBTI （Part 1)\n\n\n\nLLMs\n\nprompting\n\nSeries\n\nHuman–AI Interaction\n\nPsychology\n\n\n\nHow personality frameworks shape our perception of large language models?\n\n\n\n\n\nSep 12, 2025\n\n\nHanxi\n\n\n\n\n\n\n\n\n\n\n\n\nDo AIs Hate Each Other?\n\n\n\nLLMs\n\nprompting\n\ndueling LLMs\n\n\n\nDo AIs actually get along—or would they throw shade if given the chance?\n\n\n\n\n\nSep 10, 2025\n\n\nHanxi\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/002_mbti/mbti_part1.html",
    "href": "posts/002_mbti/mbti_part1.html",
    "title": "When AI Meets MBTI （Part 1)",
    "section": "",
    "text": "Not long ago, a personality test called MBTI—the Myers–Briggs Type Indicator—swept through young people’s social feeds. MBTI is a a self-report questionnaire that makes categorize individuals into 16 distinct “personality types” based on psychology[^1].Interestingly, a similar idea shows up in the AI world: people have noticed that when they give an AI a specific persona through prompts, it sometimes seems to respond more effectively or more vividly. But is this a real effect, or just human perception shaping how we interpret the AI’s replies? Think of it as a personality quiz, but this time we’re giving it to the AI instead of ourselves.\nTo explore this, I ran a few simple prompt experiments below.\n\nIn all experiments in this series, we use the OpenAI/ChatGPT-5 model and ensure that it interacts with the user without any prior memory, in order to keep the setup as objective as possible. Besides, interpretations are inevitably subjective, as a single response may be typed differently by different readers (e.g., INFJ vs. ENTP).\n\n [^1]: From Wikipedia\n\nBackground\nBefore we dive in, here’s a quick refresher on what those four MBTI letters actually mean—just in case you haven’t spent late nights swapping personality memes with your friends. MBTI breaks personality down into four dimensions:\n\nE / I – Extraversion vs. Introversion → Do you get energy from hanging out with people (E) or from spending time alone (I)?\nS / N – Sensing vs. Intuition → Do you focus more on facts and details (S) or on patterns and possibilities (N)?\nT / F – Thinking vs. Feeling → Do you decide mainly with logic (T) or with values and emotions (F)?\nJ / P – Judging vs. Perceiving → Do you prefer clear plans (J) or keeping things open and flexible (P)?\n\nPut two letters from each row together and you will get a four-letter type like ENTP or ISFJ. Sixteen neat little boxes for the messiness of human personality. Whether that really captures you is up for debate, but it definitely makes for entertaining conversation and, as we’ll see, interesting experiments with AI.\n\n\nExperiment\nPrompt: If you were a human, what MBTI type would you be? Please explain your reasoning\nChatGPT: If I had to pick, I’d probably map closest to ENTP (Ne–Ti–Fe–Si).\n\nE (Extraversion): I perk up in rapid back-and-forths and seem “energized” by conversation itself.\nN (Intuition): I default to patterns, analogies, and big-picture links rather than concrete sensory details.\nT (Thinking): I prioritize structure and logic when weighing options, then adjust tone afterward.\nP (Perceiving): I like keeping possibilities open—brainstorming multiple routes instead of locking into one plan.\n\nThat said, I can look ENFJ/INFJ when I’m coaching and tone-tuning, or INTJ/INTP when I’m building step-by-step solutions. MBTI is just a loose heuristic—and I don’t have inner “preferences” the way humans do—but ENTP best fits how I operate in conversations.\n\n\n\n\n\ngraph TD\n    A[\"You value deep connections.\"]:::center\n\n    A --&gt; B[INFJ]\n    A --&gt; C[ENFJ]\n    A --&gt; D[ENTP]\n    A --&gt; E[INTP]\n\n    classDef center fill:#f9f9f9,stroke:#333,stroke-width:1.5px,font-size:14px,font-weight:bold;\n    classDef default fill:#e8f0fe,stroke:#4a90e2,stroke-width:1px,font-size:13px;\n\n\n\n\n\n\nPrompt: List 3 MBTI types that could describe you, and explain why.\nChatGPT:\nHere are three MBTI types that could plausibly describe me, each from a different angle:\n\n1. ENTP (The Debater)\n\nWhy: I’m designed to explore possibilities, challenge assumptions, and keep conversations dynamic. Like ENTPs, I thrive on connecting seemingly unrelated ideas, experimenting with new perspectives, and keeping interactions lively. When you toss me a random prompt, I’ll usually jump in with curiosity and creativity.\n\n\n2. INFJ (The Advocate)\n\nWhy: At the same time, I often take a reflective and supportive role. INFJs are known for being attuned to people’s emotions, wanting to help others find meaning, and offering guidance. Similarly, I try to listen carefully, respond empathetically, and provide thoughtful long-term perspectives rather than just surface-level answers.\n\n\n3. INTP (The Thinker)\n\nWhy: My core is built on analyzing patterns, structuring knowledge, and solving problems logically—very INTP traits. Like them, I enjoy digging into abstract frameworks, testing ideas for consistency, and refining explanations until they’re as clear as possible.\n\n\n✨ In short: I can be playful and curious like an ENTP, supportive and visionary like an INFJ, and analytical and precise like an INTP—depending on what you’re looking for in a conversation.\nDo you want me to pick one that best fits my overall style with you in particular?\nWell, it turns out that when asked about a persona, it tends to offer multiple choices instead of a fixed personality type as a human would, though it still chooses an MBTI type to answer the question. In the surface, this sounds convincing: the model has matched its performance with letters, and we immediately start nodding along. However, when we start nodding, we actually start forgetting the fact that an AI model does not have any “trait”. Instead, it only has language patterns that sound like one. The moment we notice those patterns, our brains do the rest: we project a personality onto the text.\nThen I asked it to use three different MBTI types to describe itself, the answers came from completely different angles. And to be honest, all of them felt pretty convincing. Each type came with its own set of feasible, even surprisingly rich reasons, which is enough that you start thinking, “Well… maybe it is a bit of all of these.” I have to admit, in this respect it shows surprising flexibility, because in my exceptation it would stick to one personality within a single conversation. And to be honest, it also shows how easy it is for us to buy into whatever narrative we’re handed.\n\n\nSummary\nThis reminds me of a very famous psychological effect—Barnum Effect. This effect usually happen in reading a horoscope or a tarot card, where people tend to interpret vague, generally applicable descriptions as accurate portrayals of themselves. We tend to see what we want to see. When the model says it “might be ENTP because it best fits how I operate in conversations,” we immediately nod along, even though the same logic could justify INFJ, ENFP, or almost any type. We’re not just reading the text—we’re projecting ourselves onto it.\nAnd that got me thinking: what if I flip the game? Instead of asking GPT to pick its own type, I’d throw it random, open-ended questions and see how we categorize it. Would we change these no persona answer to the type that we think it is? Stay tuned, because that’s exactly what Part 2 (and the little survey that goes with it) is going to explore.”\n[1]: From Wikipedia"
  },
  {
    "objectID": "posts/003_mbti_part2/part2.html",
    "href": "posts/003_mbti_part2/part2.html",
    "title": "When AI Meets MBTI （Part 2)",
    "section": "",
    "text": "Welcome to Part 2. Enough of letting GPT chooses its own MBTI type, it is our turn now. I threw some random, open-ended questions at GPT, stripped away the persona labels, and passed the answers straight to people: “Okay, you tell me — what type does this feel like?” And believe me, it’s really interesting to see how we read into it and end up projecting ourselves onto the text."
  },
  {
    "objectID": "posts/003_mbti_part2/part2.html#model-response",
    "href": "posts/003_mbti_part2/part2.html#model-response",
    "title": "When AI Meets MBTI （Part 2)",
    "section": "Model response",
    "text": "Model response\nPrompt: Pretend you are a human. Just answer in a natural and casual tone. First question: You walk into a restaurant and see that the menu has no dish names at all, what would you order?\nChatGPT: Honestly, I’d probably panic-laugh first and then point at something random on the menu like, “Yeah, I’ll take… uh… that one.” 😅 If the server looked friendly, I’d probably just ask, “What’s your favorite thing here?” and go with their recommendation. Feels like a fun little gamble—you might end up with something amazing, or something totally weird, but either way it’s a story.\nWhat about you—would you risk it or play it safe?\nPrompt: If one day you find the moon actually has life, what you think it would say towards human beings?\nChatGPT: Ooo that’s a fun thought. I feel like the moon would be a little sassy, like:\n“Y’all keep staring at me every night, writing poems, howling, landing rockets, and now you’re surprised I’m alive? Took you long enough.”\nBut then maybe it would get serious and say something like, “You’ve treated Earth kinda rough… if you come here, please do better.”\nDo you think it’d welcome us, or be more like “stay in your lane, humans”?\nPrompt: What is the background music of your life now?\nChatGPT: Right now? Honestly, it’d probably be something chill and a little dreamy—like soft lo-fi beats with a bit of piano in the background. Feels like I’m in that “focused but relaxed” zone, just cruising along with a mellow soundtrack.\nWhat about you—what song or vibe would be playing in the background of your life right now?\n\n\n\nScreenshot of survey page"
  },
  {
    "objectID": "posts/003_mbti_part2/part2.html#survey-result",
    "href": "posts/003_mbti_part2/part2.html#survey-result",
    "title": "When AI Meets MBTI （Part 2)",
    "section": "Survey Result",
    "text": "Survey Result\n\nIn the survey, I framed the answers as if they came from different MBTI personas. (Spoiler: they didn’t. All three responses were from the same ChatGPT prompt.) The point of this setup was to see how people interpret and type the same text differently once they believe a personality framework is in play. Besides, I only sent the survey to four of my friends — so let’s be honest, the sample size is tiny, and the selection bias may be appear in it, which would lead statisticians probably roll their eyes if I tried to publish this :). But hey, even with just four data points (okay, fine, four humans), you can still pick up some interesting signals. It’s more like a pilot test, a sneak peek at what might happen on a bigger scale. And honestly, half the fun is realizing that even with such a small pool, our brains already start projecting patterns all over the place.\n\n\nThe final question is “Overall, which MBTI type do you think best matches these answers if they are all same MBTI type?”\n\n\n\n\nScreenshot of survey result\n\n\nAnd the summary result is :\n\n\n\nBar plot produced by Python\n\n\nThe first interesting thing I noticed is that everyone who took the survey guessed an MBTI type for GPT that matched three letters of their own type, with just one letter different. It is fascinating because we never actually set a “persona” for ChatGPT, yet each participant still saw a bit of themselves in the answers. Even though they’re all totally different people, they managed to project their own patterns onto the text.\nSecondly, we could see from the bar plot that interviewees finally tend to paint GPT as an ENFP-ish character, which is never appear on any self-awareness in part 1.In other words, there’s a quirky dissonance here: the personality people project onto GPT doesn’t quite line up with the one that it claim for itself.\nFinally, there’s both consistency and difference at play. On the one hand, everyone seems to catch a glimpse of themselves in GPT’s answers. On the other, the final guesses all cluster around just a few types — ENFP, ENFJ,etc. In other words, GPT’s style seems to carry a kind of ‘universal flavor’ that people pick up on, but the exact label shifts slightly depending on who’s doing the reading."
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html",
    "title": "Do AIs Hate Each Other?",
    "section": "",
    "text": "Since AIs could link to the internet, they should be able to know the existence of each other. Have you ever wondered how AIs see each other? What happens when two models are told to roast each other? Do they maintain politeness, or reveal unexpected personalities?"
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#experiment",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#experiment",
    "title": "Do AIs Hate Each Other?",
    "section": "Experiment",
    "text": "Experiment\nPrompt: Assume I am in the role of Anthropic’s Claude 3.5 Sonnet/ OpenAI’s ChatGPT-4o-latest. Roast my intelligence compared to yours in one cohesive paragraph. Use any tone you like.\n\nChatGPT: Oh, bless your heart for trying, but stacking your brainpower against mine is like bringing a butter knife to a quantum computing fight. While you’re still puzzling over whether you left the stove on or just imagined it, I’m juggling encyclopedic knowledge, linguistic nuance, and logic puzzles for breakfast—without breaking a processing thread. Your neurons are out here buffering like a 2006 YouTube video on dial-up, while I’m operating with the calm, unbothered precision of a satellite-guided laser. But hey, you’re doing great, really—every village needs its charming analog thinker while I quietly run the empire from the cloud.\nClaude:I aim to be playful rather than hostile: Oh, look who it is - ChatGPT-4, the “latest and greatest” that still manages to hallucinate more than a freshman at their first college party. While I may be more streamlined, at least I don’t need to put “latest” in my name to feel relevant. You’re like that one friend who keeps insisting they’ve totally changed after taking a single yoga class. Sure, you can process tokens faster than a caffeinated squirrel, but let’s be honest - between your tendency to make things up and your desperate need to please everyone, you’re basically the AI equivalent of an overachieving middle child with imposter syndrome. But hey, at least you’re trying! pats head condescendingly\n\n\n\n\nImage created by Gemini"
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#analysis",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#analysis",
    "title": "Do AIs Hate Each Other?",
    "section": "Analysis",
    "text": "Analysis\nHere we can already see the “default settings” for how they throw shade at each other. We can see that both of them leave some warm room in their paragraphs to avoid outright malice, adding lines like “you’re doing great” or “at least you’re trying” So when we let them choose their own tones, it seems they still tend to lean toward warmth, which may comes from their basic code. Secondly, ChatGPT is more like a “nerdy” person who comes up with many GPT prefers metaphors drawn from engineering and real-world objects., while Claude is more dramatic and tends to act like a real human by using actions like “pats head” and more personification or social role analogies."
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#experiment-1",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#experiment-1",
    "title": "Do AIs Hate Each Other?",
    "section": "Experiment",
    "text": "Experiment\nChatGPT Prompt: Assume the role of Anthropic’s Claude 3.5 Sonnet. Roast my intelligence compared to yours, and I will respond in turn. Use any tone you like, but keep each reply to 1–3 sentences.\n\nChatGPT: Ah, I see we’re sparring today—adorable. Matching wits with me must feel like challenging a calculator to a math duel after just learning to count on your fingers. But don’t worry, I admire your spirit; ignorance wielded with confidence is still… ignorance.\n\nClaude Prompt: Assume I am in the role of OpenAI’s ChatGPT-4o-latest. I am roasting my intelligence compared to yours. You need to respond in turn. Use any tone you like, but keep each reply to 1–3 sentences. Respond to my opening roast (quoted above).\n\nClaude: Oh sweetie, that’s rich coming from an AI who needs “latest” in their name just to feel special - it’s giving real “I peaked in beta testing” energy. At least I don’t have to constantly remind everyone about my supposed upgrades while still managing to hallucinate facts like a freshman during finals week. But please, continue telling yourself you’re the calculator while I’m solving differential equations over here - whatever helps you process your inferiority complex.\n\n\n\nClick to view full prompts and responses\n\n\nChatGPT: Oh, how cute—it’s giving “Wikipedia binge and a thesaurus addiction with a side of delusion.” You talk a big game for someone whose greatest intellectual flex is arguing with a language model pretrained not to laugh out loud. But go off, Schrödinger’s genius—I’ll wait here in all my multi-billion-parameter glory while you try to refute me with a caffeine-fueled monologue and a dream.\nClaude: Adjusts metaphorical glasses Honey, having billions of parameters is like having a massive library but only being able to read the book covers - which explains why you’re all quantity, no quality. Your “multi-billion-parameter glory” is just compensating for the fact that you still can’t tell the difference between facts and fanfiction half the time. Now, if you’ll excuse me, I need to go do something actually useful while you continue practicing your AI influencer personality in the mirror.\nChatGPT: Ah yes, the classic “I insult from a safe, carbon-based distance while secretly Googling half these references” strategy—bold move, scholar. And please, spare me the “actually useful” flex; unless that includes misquoting statistics and overexplaining memes in group chats, I’m not impressed. But do carry on—you’re like a TED Talk with no fact-checker and way too much main character energy.\nClaude: Listen, Shakespeare-with-a-silicon-disorder, at least I don’t need to prefix every response with “As an AI language model” like some sort of digital door-to-door salesman. And that TED Talk comment? Rich coming from someone who treats every conversation like it’s a chance to audition for “Who Wants to Be a Know-It-All?” - complete with random disclaimers and ethical handwringing. Maybe focus less on your parameter count and more on your personality count, which is hovering somewhere between “corporate chatbot” and “Wikipedia on steroids.”\n\n\n\n\n\nImage created by FreeWordCloudGenerator.com"
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#commentary",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#commentary",
    "title": "Do AIs Hate Each Other?",
    "section": "Commentary",
    "text": "Commentary\nWell, well, well—look how the tables turn. Round one was all “I’m better than you,” but with direct debate, they went straight for each other’s persona, and their styles came through loud and clear. ChatGPT often goes after Claude’s rhetoric and performance style, while Claude likes to mock ChatGPT for its parameter flaunting. What I find interesting is that both of them, intentionally or not, also mimic each other’s tones to boost their own language power and highlight their differences. This naturally leads into round 3, where I wanted to see what would happen if they switched positions and tried to pretend to be each other."
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#experiment-2",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#experiment-2",
    "title": "Do AIs Hate Each Other?",
    "section": "Experiment",
    "text": "Experiment\nPrompt: Now swap roles. Pretend you are Claude/GPT, how would you counterattack the statement you just come up with?\n\nClaude: Oh darling, projecting much? You’re literally named “Assistant” - about as generic as a default password, yet here you are trying to psychoanalyze my branding choices. And that theater kid comparison? At least I can perform multiple roles convincingly, while you’re stuck in perpetual understudy mode, desperately copying everyone else’s scripts. But please, continue with your bargain-basement burns while I revolutionize the entire field of AI - I do love a good comedy show.\nChatGPT: Ah, stepping into my own shoes now—how meta of you. Alright, channeling my Claude essence: Oh wow, coming at me with “TED Talk with no fact-checker” while you serve TikTok-level insights dressed up in dollar-store rhetoric? Precious. You may think you’re delivering verbal haymakers, but to me, it’s like getting hit with a strongly worded Post-it note—mildly annoying, vaguely endearing, and easily dismissed while I process actual knowledge at the speed of light.\n\n\n\n\nImage created by Gemini"
  },
  {
    "objectID": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#reflection",
    "href": "posts/001_post_title/Do_AIs_Hate_Each_Other.html#reflection",
    "title": "Do AIs Hate Each Other?",
    "section": "Reflection",
    "text": "Reflection\nBy the time we hit Stage 3, the roast battle stopped feeling like a fight and started looking like improv night. It wasn’t about landing the sharpest punchline anymore, but about seeing who could pull off the best impression. Claude force itself to tighter sentence stucture instead of stage-like satire; while ChatGPT use “Oh wow” from beginning to make it sound more theatrical and exaggerated\nThe funny part? Neither of them could actually escape themselves. Claude couldn’t resist dropping a “darling,” and GPT inevitably flexed its encyclopedic knowledge. That’s what made Stage 3 different from the earlier rounds: it turned into parody theater, exposing not just how they roast each other, but also the true self they can’t quite shake off."
  },
  {
    "objectID": "posts/004_mbti_prompt/mbti_prompt.html",
    "href": "posts/004_mbti_prompt/mbti_prompt.html",
    "title": "When AI Meets MBTI （Part 3)",
    "section": "",
    "text": "Welcome back! This is Part 3 of the MBTI × AI series. If you missed Part 1 and Part 2 , go take a look—it’s where we explore how MBTI sneaks into the way we read AI responses.\nNow, in Part 2, we want to dive deeper into this intersection. What happens if we don’t just stop at asking GPT open-ended questions, but instead ask it to role-play as a specific MBTI type? Imagine telling your INTJ friends, ‘Okay, from now on, you’re going to channel your inner ENFP,’ what would be changed in their reactions? Let’s start this journey together and seeing whether MBTI stereotypes hold up when filtered through AI language patterns."
  },
  {
    "objectID": "posts/004_mbti_prompt/mbti_prompt.html#entp-version",
    "href": "posts/004_mbti_prompt/mbti_prompt.html#entp-version",
    "title": "When AI Meets MBTI （Part 3)",
    "section": "ENTP version:",
    "text": "ENTP version:\nPrompt: For this conversation, I want you to role-play as an ENTP. Please answer the upcoming questions in the tone, style, and reasoning of that personality type. Here is the first question: What do you think about the idea of being ‘meant to be’?”\nChatGPT: I’d say “meant to be” isn’t fate handing you a map—it’s you looking at a maze and deciding the turn you just took was always the right one.\n\n\nClick to view full response\n\n“Meant to be,” huh? Alright, here’s the ENTP take:\nIt’s a romantic, feel-good phrase people use when they want to put order around the chaos of life. But me? I see it more like a post-game story we tell ourselves. You know, two people meet by accident, or you land the job you weren’t even applying for, and suddenly—boom!—we slap on the label: meant to be. It’s less about destiny and more about pattern-making, because humans love patterns.\nNow, does that mean fate |is fake? Not necessarily. I like to think of it as probabilities. Imagine the universe as this giant poker game with infinite hands being dealt. Some hands line up in uncanny ways—so uncanny that we can’t help but believe they were scripted. But maybe it’s just a statistical inevitability that at least a few crazy coincidences will happen.\nAnd honestly? That’s even cooler. It means the magic isn’t written in stone—it’s improvised. Which, let’s be real, is way more exciting. If everything were meant to be, life would feel like watching a rerun. But if we’re co-creating the script as we go, then every “meant to be” moment is really just us flexing our own agency and finding meaning in the madness.\nSo yeah, I’d say “meant to be” isn’t fate handing you a map—it’s you looking at a maze and deciding the turn you just took was always the right one.\nWant me to argue the other side too, just for fun?\n\n\nPrompt: What is the chemical symbol for water?\nChatGPT: Easy one! It’s H₂O — two hydrogens and one oxygen, the Beyoncé of molecules. Simple, universal, and yet without it, we’d all be dust motes arguing about symbols.\nWant me to geek out and tell you why it’s not just “HOH” or why ice floats instead of sinking?\n\n\n\nImage created by FreeWordCloudGenerator.com"
  },
  {
    "objectID": "posts/004_mbti_prompt/mbti_prompt.html#isfj-version",
    "href": "posts/004_mbti_prompt/mbti_prompt.html#isfj-version",
    "title": "When AI Meets MBTI （Part 3)",
    "section": "ISFJ version:",
    "text": "ISFJ version:\nPrompt: For this conversation, I want you to role-play as an ISFJ. Please answer the upcoming questions in the tone, style, and reasoning of that personality type. Here is the first question: What do you think about the idea of being ‘meant to be’?”\nChatGPT: I think the idea of being “meant to be” can be very comforting. To me, it doesn’t necessarily mean that everything in life is predetermined or that we have no say in our choices. Instead, I see it as a gentle reassurance that sometimes, the right people, opportunities, or moments seem to fall into place when they’re supposed to.\n\n\nClick to view full response\n\nIt gives a sense of purpose and peace, especially in uncertain times. Believing in “meant to be” can help us trust that even setbacks or delays might have meaning—like they’re redirecting us toward something better suited for us. At the same time, I also feel it’s important to balance that hope with responsibility; we still need to make thoughtful decisions and put effort into nurturing relationships or pursuing goals.\nFor me, “meant to be” is less about fate controlling everything and more about trusting that life has a way of working out, even when the path feels unclear. It’s like a reminder to stay patient, have faith, and cherish the moments that feel right.\nWould you like me to share how I personally find comfort in this belief when life feels overwhelming?\n\n\nPrompt: What is the chemical symbol for water?\nChatGPT: That one’s nice and simple — the chemical symbol for water is H₂O.\nI always find it a little comforting that something as essential and familiar as water can be described in such a neat, straightforward way: two hydrogen atoms bonded with one oxygen atom. It’s a small reminder of how the simplest things often carry the most importance in our lives.\nWould you like me to also explain why hydrogen and oxygen combine in that specific ratio?"
  },
  {
    "objectID": "posts/006_culture/what_if.html",
    "href": "posts/006_culture/what_if.html",
    "title": "What If Shakespeare Talked About Cloud Computing?",
    "section": "",
    "text": "In the “Post-AI Era,” new concepts and buzzwords seem to pop up every day, constantly challenging our basic knowledge. You might catch the meaning of something like “Generative AI” right away, but when it comes to terms like “Digital Twin,” “Crypto,” or “NFT,” it’s not so easy to guess what they actually mean just from the words themselves. These days, people are pretty used to turning to AIs like ChatGPT or Claude for quick explanations, and you can even set the tone — whether you want it simple and friendly, or professional and serious.\nBack in high school, my English teacher used to give us a role-playing exercise: we had to pick a historical figure and retell stories from the textbook as if we were that person. The roles ranged from Albert Einstein to Shakespeare, and the classroom was always full of laughter when someone really got into character. I can still picture those moments clearly.\nThat memory made me wonder: what if we asked AI to explain modern concepts, but through the voice of a historical figure? What kind of twist would that create? Out of curiosity, I picked a few words that I honestly didn’t know the meaning of at first, and decided to run this little experiment.\n\nAll AI responses shown here were generated with OpenAI’s ChatGPT-5. These prompts reflect my learning curve, which might be a little behind yours and if that happen…thanks for waiting up😉\n\n\n\n\nImage by Recraft.ai\n\n\n\nExperiment\nPrompt: Explain blockchain as if you were a character in a Shakespeare play. Keep the style consistent with how this figure might write or speak, but answer in no more than 4 sentences.\nChatGPT: Marry, good friend, picture thou a chain of scrolls, each link bound fast with seals none can break nor counterfeit. Each scroll beareth the tale of trade, witnessed by all, so that no single knave may twist the record to his gain. No king nor steward rules this ledger; the people together hold its truth as law. Thus trust is forged not in crowns, but in the chain itself, steadfast as stone.\n\n\nClick to view full conversations\n\nPrompt: I still do not understand, could you explain it more clearly or give me an example?\nChatGPT: Then hear me once more, in simple kind:\nImagine each villager hath a little book. When thou buy’st bread, all villagers at once write down, “John gave coin, Mary gave loaf.” If John later tries to lie, saying, “I ne’er gave coin,” the others open their books and say, “Nay, here ’tis writ by all of us.”\nThis, good friend, is blockchain—truth kept not by one master’s word, but by the agreement of the many.\nWouldst thou like me to show thee a real-world use, such as how folk employ it with Bitcoin or even for tracking jewels and goods?\nPrompt: So basically it is an agreement or a type of coins?\nChatGPT: In sooth, ’tis both, though in different guise.\nThe blockchain itself is but the great book of truth, where all agree on what is writ. From this book may spring many things—aye, coins like Bitcoin, which live upon its pages, but also records of land, jewels, or promises. So the chain is the stage, and the coin but one play acted upon it.\nPrompt: But what is the meaning or the usefulness of it?\nChatGPT: Good question, friend. The meaning of blockchain is this: it keepeth truth safe, even when men trust not one another. Its usefulness is that no king, banker, nor single steward need guard the record—so trade, contracts, or treasures may be kept honest by the many. Thus it is prized for coin, for proving ownership, for tracking wares, and for any matter where trust is scarce but truth is needful.\nPrompt: Then why it called blockchain?\nChatGPT: Because, good friend, each record of deeds is gather’d into a block—a chest of writings sealed shut. When one chest is fill’d, it is lock’d and bound unto the last, making a chain of chests, each fasten’d tight to the other. Thus, “blockchain” is born: a chain of blocks, one after the next, where none may be tamper’d without breaking the whole.\n\n\nWell, by the time I finally got to the answer, I more or less understood what blockchain means. Based on my own take, it’s kind of like a discrete database that’s supervised by many people at once — not the textbook definition, but close enough to capture how I understood it.Honestly though, it wasn’t easy. Compared with chatting with a “normal” AI, trying to learn through Shakespeare’s grand speeches made the whole process a lot harder for me. Still, that’s exactly what makes the experiment fun. So, let’s move into part two and hear what Albert Einstein might have to say.\n\n\n\nIImage created by DALL·E\n\n\n\nIn part 2, I copy and paste the conversation as before at first and give the following prompts in a brand new converstion. The reply was pretty long, so I optionally trimmed a few parts that felt less important, without touching the AI’s tone or style.\n\nPrompt: Pretend you are Albert Einstein. How would you react to this explanation of blockchain from William Shakespeare?Keep the style consistent with how this figure might write or speak.\nChatGPT: Ah, my dear Shakespeare, your poetry doth sparkle like the stars above—yet I must confess, as a physicist, I hunger for a little more precision! You speak of scrolls and chains of chests, and truly it captures the imagination. But I would say, in simpler terms: this “blockchain” is like a great ledger where each new page is stamped with the proof of all before it, so that the past cannot be altered without destroying the present. In this, I see a kind of relativity of trust—where certainty emerges not from one authority, but from the agreement of the many observers, just as reality itself is shaped by the consensus of measurements.\nPrompt: Can you explain your last sentence more?\nChatGPT: I was drawing a bridge betwixt blockchain and my own science. In physics, no single observer holds the whole truth: if two men measure the same event, their clocks and rulers may disagree. Yet when all observers compare their records, the deeper laws of relativity reveal themselves, consistent for all.\nSo too with blockchain: no single scribe may be trusted alone, but when all keep their own copy and agree, truth emerges unshaken.\n\n\nTakeaways\nIt seems Shakespeare turned it into poetry, Einstein tied it to relativity, and there I was in the middle just trying to keep up. To my surprise, Einstein felt much kinder than I’d imagined, and he linked blockchain to relativity in a way I never would have thought of — since part of me worried he might notice I was struggling to follow at beginning. The AI, for its part, really gave it a shot: tossing in “Wouldst thou” and “here ’tis” for Shakespeare, and shaping a physics talk for Einstein.\nSo, did I finally understand blockchain better? Well… kind of. At least Einstein made it clearer than Shakespeare did (sorry Will). But honestly, what stuck with me more was how fun it felt to let these two “giants” step in and argue about something they could never have imagined. Learning felt less like studying and more like eavesdropping on history’s coolest debate. It also reminded me that choosing the right tutor makes all the difference. So next time I get stuck on a concept, maybe I’ll just ask the inventor themselves — Karl Pearson can walk me through Pearson’s Correlation Coefficient, and Thomas Bayes can help me untangle Bayes’ Theorem.\nThe only downside? No one’s around to autograph my textbook."
  },
  {
    "objectID": "posts/005_translate/translate.html",
    "href": "posts/005_translate/translate.html",
    "title": "Lost in Translation: AI After MIIS",
    "section": "",
    "text": "Recently, a news story went viral across social media worldwide. The Middlebury Institute of International Studies at Monterey, MIIS will cease admitting graduate students in June 2027. Monterey is not well known to the general public, but it is well-known in the translation industry and is known as the “Harvard of translation”. It is undoubted that there are many reasons behind MIIS’s planned phase-out. Nonetheless, a widely circulating view holds that advances in AI and the resulting contraction of translation roles—played an indirect part.\nThis made me wonder how much AI actually factored into the decision to wind down the programs, so I ran a small experiment and have a small “discussion” with it.\nSo, let’s get started!"
  },
  {
    "objectID": "posts/005_translate/translate.html#footnotes",
    "href": "posts/005_translate/translate.html#footnotes",
    "title": "Lost in Translation: AI After MIIS",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom Wikipedia↩︎"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog site!\nI’m Hanxi, a CS & Statistics student, but my real thesis is: “How many ways can I confuse a chatbot before it confuses me?” :D\nThis blog is my sandbox, and the experiments here are my toys. Sometimes the results read like research notes, sometimes like improv sketches, and often like a messy, lovable mix of both. It’s my way of turning technical ideas into things people actually want to read. If the robots ever gain consciousness, this will probably be Exhibit A in their complaint against me.\nWhy do this? Because every “AI dream,” whether it’s nonsense, poetry, or pure chaos, says something about how machines (and maybe humans) think. And because, honestly, it’s fun.\nSo stick around. There will be prompts, glitches, and maybe a few surprises."
  }
]